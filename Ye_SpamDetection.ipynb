{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alexander Ye, Spam Detection Classification\n",
    "### CS89.21, 23F, Vosoughi\n",
    "\n",
    "Creating a classifier for detecting spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each line in the SPAM.csv dataset corresponds to one message and has a label of either \"ham\" or \"spam\". In this assignment, you are experimenting with different features and models to create the best spam detector possible.  \n",
    "\n",
    "I tested a combination of: <br> \n",
    "(1) Logistic Regression (LR) <br> \n",
    "(2) Random Forest (RF) <br> \n",
    "\n",
    "(3) with and without lowercasing <br> \n",
    "(4) with and without stopword removal  <br> \n",
    "(5) with and without lemmatization <br>\n",
    "\n",
    "(6) unigrams <br>\n",
    "(7) unigrams and bigrams <br>\n",
    "(8) unigrams, bigrams and trigrams <br>\n",
    "(9) tfidf unigrams <br>\n",
    "(10) tfidf  unigrams and bigrams <br>\n",
    "(11) tfidf unigrams, bigrams and trigrams  <br>\n",
    "\n",
    "That's 2 model types x 8 possible prepreocessing combinations x 6 possible features = 96 models <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "spam_df = pd.read_csv('SPAM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5     spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6      ham  Even my brother is not like to speak with me. ...\n",
       "7      ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8     spam  WINNER!! As a valued network customer you have...\n",
       "9     spam  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "spam_df['Tokenized_Message'] = spam_df['Message'].apply(nltk.word_tokenize) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>Tokenized_Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>[Go, until, jurong, point, ,, crazy, .., Avail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[Ok, lar, ..., Joking, wif, u, oni, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[U, dun, say, so, early, hor, ..., U, c, alrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[Nah, I, do, n't, think, he, goes, to, usf, ,,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>[FreeMsg, Hey, there, darling, it, 's, been, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>[Even, my, brother, is, not, like, to, speak, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>[As, per, your, request, 'Melle, Melle, (, Oru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>[WINNER, !, !, As, a, valued, network, custome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>[Had, your, mobile, 11, months, or, more, ?, U...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...   \n",
       "1      ham                      Ok lar... Joking wif u oni...   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      ham  U dun say so early hor... U c already then say...   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "5     spam  FreeMsg Hey there darling it's been 3 week's n...   \n",
       "6      ham  Even my brother is not like to speak with me. ...   \n",
       "7      ham  As per your request 'Melle Melle (Oru Minnamin...   \n",
       "8     spam  WINNER!! As a valued network customer you have...   \n",
       "9     spam  Had your mobile 11 months or more? U R entitle...   \n",
       "\n",
       "                                   Tokenized_Message  \n",
       "0  [Go, until, jurong, point, ,, crazy, .., Avail...  \n",
       "1           [Ok, lar, ..., Joking, wif, u, oni, ...]  \n",
       "2  [Free, entry, in, 2, a, wkly, comp, to, win, F...  \n",
       "3  [U, dun, say, so, early, hor, ..., U, c, alrea...  \n",
       "4  [Nah, I, do, n't, think, he, goes, to, usf, ,,...  \n",
       "5  [FreeMsg, Hey, there, darling, it, 's, been, 3...  \n",
       "6  [Even, my, brother, is, not, like, to, speak, ...  \n",
       "7  [As, per, your, request, 'Melle, Melle, (, Oru...  \n",
       "8  [WINNER, !, !, As, a, valued, network, custome...  \n",
       "9  [Had, your, mobile, 11, months, or, more, ?, U...  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labeling the target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0, 1, 0, 0, 1, 1]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_numeric = []\n",
    "\n",
    "for email in spam_df['Category']:\n",
    "    if email == 'spam':\n",
    "        category_numeric.append(1)\n",
    "    elif email == 'ham':\n",
    "        category_numeric.append(0)\n",
    "    else:\n",
    "        category_numeric.append('NULL')\n",
    "category_numeric[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.929460580912863"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# single run test with no preprocessing\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.metrics import f1_score\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(spam_df, category_numeric, \n",
    "#                                                     test_size=0.15, random_state=20)\n",
    "\n",
    "# LR = LogisticRegression()\n",
    "\n",
    "# vectorizer = CountVectorizer(ngram_range=(1,1))\n",
    "# features = vectorizer.fit_transform(X_train['Message'])\n",
    "# test_features = vectorizer.transform(X_test['Message'])\n",
    "\n",
    "# LR.fit(features, y_train)\n",
    "# y_pred = LR.predict(test_features)\n",
    "\n",
    "# f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def preprocess(spam_df,lowercase=False,remove_stopwords=False,lemmatize=False):\n",
    "    spam_df['Filtered_Message'] = spam_df['Tokenized_Message']\n",
    "    \n",
    "    if lowercase:\n",
    "        spam_df['Filtered_Message'] = spam_df['Tokenized_Message'].apply(lambda x: [token.lower() for token in x])\n",
    "\n",
    "    if remove_stopwords:\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        spam_df['Filtered_Message'] = spam_df['Filtered_Message'].apply(lambda x: [token for token in x if token not in stop_words])\n",
    "\n",
    "    if lemmatize:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        spam_df['Filtered_Message'] = spam_df['Filtered_Message'].apply(lambda x: [lemmatizer.lemmatize(token) for token in x])\n",
    "\n",
    "    spam_df['Filtered_Message'] = spam_df['Filtered_Message'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train_model(model_type,train_features, train_labels):\n",
    "    trained_model = None\n",
    "    \n",
    "    if model_type == 'LR':\n",
    "        trained_model = LogisticRegression()\n",
    "    elif model_type == 'RF':\n",
    "        trained_model = RandomForestClassifier()\n",
    "        \n",
    "    trained_model.fit(train_features, train_labels)\n",
    "    \n",
    "    return trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def evaluate_model(trained_model,metric,eval_features,eval_labels):\n",
    "    y_pred = trained_model.predict(eval_features)\n",
    "    \n",
    "    if metric == 'f1':\n",
    "        model_eval = f1_score(eval_labels, y_pred)\n",
    "    elif metric == 'weighted_f1':\n",
    "        model_eval = f1_score(eval_labels, y_pred, average='weighted')\n",
    "    elif metric == 'accuracy':\n",
    "        model_eval = accuracy_score(eval_labels, y_pred)\n",
    "    \n",
    "    return model_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def run_model(spam_df, category_numeric, model_type = 'LR', lowercase=False, remove_stopwords=False,lemmatize=False, \n",
    "              tfidf=False, ngram_range=(1,1)):\n",
    "\n",
    "    preprocess(spam_df, lowercase, remove_stopwords, lemmatize)\n",
    "    \n",
    "    X = spam_df['Filtered_Message']\n",
    "    y = category_numeric\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=20)\n",
    "    \n",
    "    vectorizer = CountVectorizer(ngram_range=ngram_range)\n",
    "    if tfidf:\n",
    "        vectorizer = TfidfVectorizer(ngram_range=ngram_range)\n",
    "\n",
    "    features = vectorizer.fit_transform(X_train)\n",
    "    test_features = vectorizer.transform(X_test)\n",
    "\n",
    "    model = train_model(model_type, features, y_train)\n",
    "    \n",
    "    metrics_data = []\n",
    "    \n",
    "    # metrics from train data\n",
    "    for metric in ['f1', 'weighted_f1', 'accuracy']:\n",
    "        data = evaluate_model(model, metric, features, y_train)\n",
    "        metrics_data.append(data)\n",
    "        \n",
    "    # metrics from test data\n",
    "    for metric in ['f1', 'weighted_f1', 'accuracy']:\n",
    "        data = evaluate_model(model, metric, test_features, y_test)\n",
    "        metrics_data.append(data)\n",
    "    \n",
    "    # building in confusion matrix into DataFrame\n",
    "    y_pred = model.predict(test_features)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return metrics_data, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.9853181076672105,\n",
       "  0.9961782111219822,\n",
       "  0.9961993243243243,\n",
       "  0.9288702928870293,\n",
       "  0.9792042677748827,\n",
       "  0.9796650717703349],\n",
       " array([[708,   2],\n",
       "        [ 15, 111]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_model(spam_df, category_numeric, model_type = 'LR', lowercase=False, remove_stopwords=True,lemmatize=False, \n",
    "              tfidf=False, ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>lowercased</th>\n",
       "      <th>stopwords_removed</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "      <th>tfidf unigrams</th>\n",
       "      <th>tfidf bigrams</th>\n",
       "      <th>tfidf trigrams</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>weighted_f1_train</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>weighted_f1_test</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>confusion_matrix_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.987775</td>\n",
       "      <td>0.996816</td>\n",
       "      <td>0.996833</td>\n",
       "      <td>0.929461</td>\n",
       "      <td>0.979279</td>\n",
       "      <td>0.979665</td>\n",
       "      <td>[[707, 3], [14, 112]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.892444</td>\n",
       "      <td>0.973302</td>\n",
       "      <td>0.974451</td>\n",
       "      <td>0.878261</td>\n",
       "      <td>0.965161</td>\n",
       "      <td>0.966507</td>\n",
       "      <td>[[707, 3], [25, 101]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.995958</td>\n",
       "      <td>0.998942</td>\n",
       "      <td>0.998944</td>\n",
       "      <td>0.927660</td>\n",
       "      <td>0.979050</td>\n",
       "      <td>0.979665</td>\n",
       "      <td>[[710, 0], [17, 109]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.839552</td>\n",
       "      <td>0.961170</td>\n",
       "      <td>0.963682</td>\n",
       "      <td>0.844037</td>\n",
       "      <td>0.956634</td>\n",
       "      <td>0.959330</td>\n",
       "      <td>[[710, 0], [34, 92]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.995958</td>\n",
       "      <td>0.998942</td>\n",
       "      <td>0.998944</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.977776</td>\n",
       "      <td>0.978469</td>\n",
       "      <td>[[710, 0], [18, 108]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.762948</td>\n",
       "      <td>0.944497</td>\n",
       "      <td>0.949747</td>\n",
       "      <td>0.796209</td>\n",
       "      <td>0.944289</td>\n",
       "      <td>0.948565</td>\n",
       "      <td>[[709, 1], [42, 84]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.986122</td>\n",
       "      <td>0.996389</td>\n",
       "      <td>0.996410</td>\n",
       "      <td>0.938272</td>\n",
       "      <td>0.981782</td>\n",
       "      <td>0.982057</td>\n",
       "      <td>[[707, 3], [12, 114]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LR</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.891459</td>\n",
       "      <td>0.973070</td>\n",
       "      <td>0.974240</td>\n",
       "      <td>0.892704</td>\n",
       "      <td>0.969074</td>\n",
       "      <td>0.970096</td>\n",
       "      <td>[[707, 3], [22, 104]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LR</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.995958</td>\n",
       "      <td>0.998942</td>\n",
       "      <td>0.998944</td>\n",
       "      <td>0.919831</td>\n",
       "      <td>0.976672</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>[[708, 2], [17, 109]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LR</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.846797</td>\n",
       "      <td>0.962834</td>\n",
       "      <td>0.965160</td>\n",
       "      <td>0.849315</td>\n",
       "      <td>0.958001</td>\n",
       "      <td>0.960526</td>\n",
       "      <td>[[710, 0], [33, 93]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LR</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.995958</td>\n",
       "      <td>0.998942</td>\n",
       "      <td>0.998944</td>\n",
       "      <td>0.927660</td>\n",
       "      <td>0.979050</td>\n",
       "      <td>0.979665</td>\n",
       "      <td>[[710, 0], [17, 109]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LR</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.945539</td>\n",
       "      <td>0.950591</td>\n",
       "      <td>0.801887</td>\n",
       "      <td>0.945709</td>\n",
       "      <td>0.949761</td>\n",
       "      <td>[[709, 1], [41, 85]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LR</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.985318</td>\n",
       "      <td>0.996178</td>\n",
       "      <td>0.996199</td>\n",
       "      <td>0.928870</td>\n",
       "      <td>0.979204</td>\n",
       "      <td>0.979665</td>\n",
       "      <td>[[708, 2], [15, 111]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LR</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.875112</td>\n",
       "      <td>0.969176</td>\n",
       "      <td>0.970650</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.962061</td>\n",
       "      <td>0.964115</td>\n",
       "      <td>[[710, 0], [30, 96]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LR</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.998730</td>\n",
       "      <td>0.998733</td>\n",
       "      <td>0.924370</td>\n",
       "      <td>0.977941</td>\n",
       "      <td>0.978469</td>\n",
       "      <td>[[708, 2], [16, 110]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LR</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.806513</td>\n",
       "      <td>0.953804</td>\n",
       "      <td>0.957348</td>\n",
       "      <td>0.827907</td>\n",
       "      <td>0.952495</td>\n",
       "      <td>0.955742</td>\n",
       "      <td>[[710, 0], [37, 89]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LR</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.998730</td>\n",
       "      <td>0.998733</td>\n",
       "      <td>0.927660</td>\n",
       "      <td>0.979050</td>\n",
       "      <td>0.979665</td>\n",
       "      <td>[[710, 0], [17, 109]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LR</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.735025</td>\n",
       "      <td>0.938535</td>\n",
       "      <td>0.944890</td>\n",
       "      <td>0.770732</td>\n",
       "      <td>0.938236</td>\n",
       "      <td>0.943780</td>\n",
       "      <td>[[710, 0], [47, 79]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LR</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.985318</td>\n",
       "      <td>0.996178</td>\n",
       "      <td>0.996199</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.980463</td>\n",
       "      <td>0.980861</td>\n",
       "      <td>[[708, 2], [14, 112]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LR</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.872072</td>\n",
       "      <td>0.968471</td>\n",
       "      <td>0.970017</td>\n",
       "      <td>0.862222</td>\n",
       "      <td>0.961040</td>\n",
       "      <td>0.962919</td>\n",
       "      <td>[[708, 2], [29, 97]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model  lowercased  stopwords_removed  lemmatized  unigrams  bigrams  \\\n",
       "0     LR       False              False       False      True    False   \n",
       "1     LR       False              False       False     False    False   \n",
       "2     LR       False              False       False      True     True   \n",
       "3     LR       False              False       False     False    False   \n",
       "4     LR       False              False       False      True     True   \n",
       "5     LR       False              False       False     False    False   \n",
       "6     LR       False              False        True      True    False   \n",
       "7     LR       False              False        True     False    False   \n",
       "8     LR       False              False        True      True     True   \n",
       "9     LR       False              False        True     False    False   \n",
       "10    LR       False              False        True      True     True   \n",
       "11    LR       False              False        True     False    False   \n",
       "12    LR       False               True       False      True    False   \n",
       "13    LR       False               True       False     False    False   \n",
       "14    LR       False               True       False      True     True   \n",
       "15    LR       False               True       False     False    False   \n",
       "16    LR       False               True       False      True     True   \n",
       "17    LR       False               True       False     False    False   \n",
       "18    LR       False               True        True      True    False   \n",
       "19    LR       False               True        True     False    False   \n",
       "\n",
       "    trigrams  tfidf unigrams  tfidf bigrams  tfidf trigrams  f1_train  \\\n",
       "0      False           False          False           False  0.987775   \n",
       "1      False            True          False           False  0.892444   \n",
       "2      False           False          False           False  0.995958   \n",
       "3      False            True           True           False  0.839552   \n",
       "4       True           False          False           False  0.995958   \n",
       "5      False            True           True            True  0.762948   \n",
       "6      False           False          False           False  0.986122   \n",
       "7      False            True          False           False  0.891459   \n",
       "8      False           False          False           False  0.995958   \n",
       "9      False            True           True           False  0.846797   \n",
       "10      True           False          False           False  0.995958   \n",
       "11     False            True           True            True  0.767857   \n",
       "12     False           False          False           False  0.985318   \n",
       "13     False            True          False           False  0.875112   \n",
       "14     False           False          False           False  0.995146   \n",
       "15     False            True           True           False  0.806513   \n",
       "16      True           False          False           False  0.995146   \n",
       "17     False            True           True            True  0.735025   \n",
       "18     False           False          False           False  0.985318   \n",
       "19     False            True          False           False  0.872072   \n",
       "\n",
       "    weighted_f1_train  accuracy_train   f1_test  weighted_f1_test  \\\n",
       "0            0.996816        0.996833  0.929461          0.979279   \n",
       "1            0.973302        0.974451  0.878261          0.965161   \n",
       "2            0.998942        0.998944  0.927660          0.979050   \n",
       "3            0.961170        0.963682  0.844037          0.956634   \n",
       "4            0.998942        0.998944  0.923077          0.977776   \n",
       "5            0.944497        0.949747  0.796209          0.944289   \n",
       "6            0.996389        0.996410  0.938272          0.981782   \n",
       "7            0.973070        0.974240  0.892704          0.969074   \n",
       "8            0.998942        0.998944  0.919831          0.976672   \n",
       "9            0.962834        0.965160  0.849315          0.958001   \n",
       "10           0.998942        0.998944  0.927660          0.979050   \n",
       "11           0.945539        0.950591  0.801887          0.945709   \n",
       "12           0.996178        0.996199  0.928870          0.979204   \n",
       "13           0.969176        0.970650  0.864865          0.962061   \n",
       "14           0.998730        0.998733  0.924370          0.977941   \n",
       "15           0.953804        0.957348  0.827907          0.952495   \n",
       "16           0.998730        0.998733  0.927660          0.979050   \n",
       "17           0.938535        0.944890  0.770732          0.938236   \n",
       "18           0.996178        0.996199  0.933333          0.980463   \n",
       "19           0.968471        0.970017  0.862222          0.961040   \n",
       "\n",
       "    accuracy_test  confusion_matrix_test  \n",
       "0        0.979665  [[707, 3], [14, 112]]  \n",
       "1        0.966507  [[707, 3], [25, 101]]  \n",
       "2        0.979665  [[710, 0], [17, 109]]  \n",
       "3        0.959330   [[710, 0], [34, 92]]  \n",
       "4        0.978469  [[710, 0], [18, 108]]  \n",
       "5        0.948565   [[709, 1], [42, 84]]  \n",
       "6        0.982057  [[707, 3], [12, 114]]  \n",
       "7        0.970096  [[707, 3], [22, 104]]  \n",
       "8        0.977273  [[708, 2], [17, 109]]  \n",
       "9        0.960526   [[710, 0], [33, 93]]  \n",
       "10       0.979665  [[710, 0], [17, 109]]  \n",
       "11       0.949761   [[709, 1], [41, 85]]  \n",
       "12       0.979665  [[708, 2], [15, 111]]  \n",
       "13       0.964115   [[710, 0], [30, 96]]  \n",
       "14       0.978469  [[708, 2], [16, 110]]  \n",
       "15       0.955742   [[710, 0], [37, 89]]  \n",
       "16       0.979665  [[710, 0], [17, 109]]  \n",
       "17       0.943780   [[710, 0], [47, 79]]  \n",
       "18       0.980861  [[708, 2], [14, 112]]  \n",
       "19       0.962919   [[708, 2], [29, 97]]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['model','lowercased','stopwords_removed', 'lemmatized', 'unigrams', \n",
    "                          'bigrams', 'trigrams', 'tfidf unigrams', 'tfidf bigrams','tfidf trigrams', \n",
    "                          'f1_train', 'weighted_f1_train', 'accuracy_train', 'f1_test', \n",
    "                          'weighted_f1_test', 'accuracy_test', 'confusion_matrix_test'])\n",
    "\n",
    "row = []\n",
    "i=0\n",
    "models = ['LR', 'RF']\n",
    "\n",
    "for model in models:\n",
    "    for lowercase in [False, True]:\n",
    "        for remove_stopwords in [False, True]:\n",
    "            for lemmatize in [False, True]:\n",
    "                for n_grams in [[True, False, False], [True, True, False], [True,True,True]]:\n",
    "                    for tfidf in [False, True]:\n",
    "                        \n",
    "                        # Fill out boolean labels\n",
    "                        row.append(model)\n",
    "                        row.append(lowercase)\n",
    "                        row.append(remove_stopwords)\n",
    "                        row.append(lemmatize)\n",
    "                        if tfidf:\n",
    "                            row.extend([False, False, False])\n",
    "                            row.extend(n_grams)\n",
    "                        else:\n",
    "                            row.extend(n_grams)\n",
    "                            row.extend([False, False, False])\n",
    "                        \n",
    "                        n_gram_len = sum(n_grams)\n",
    "                        res, cm = run_model(spam_df, category_numeric, model, lowercase, remove_stopwords,\n",
    "                                        lemmatize, tfidf, ngram_range=(1,n_gram_len))\n",
    "                        \n",
    "                        row.extend(res)\n",
    "                        row.append(cm)\n",
    "    \n",
    "                        df.loc[i] = row\n",
    "                        i = i+1\n",
    "                        row = []\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 17)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with the best weighted f1 according to the train set:\n",
      "model                                       RF\n",
      "lowercased                               False\n",
      "stopwords_removed                        False\n",
      "lemmatized                               False\n",
      "unigrams                                  True\n",
      "bigrams                                  False\n",
      "trigrams                                 False\n",
      "tfidf unigrams                           False\n",
      "tfidf bigrams                            False\n",
      "tfidf trigrams                           False\n",
      "f1_train                                   1.0\n",
      "weighted_f1_train                          1.0\n",
      "accuracy_train                             1.0\n",
      "f1_test                               0.899563\n",
      "weighted_f1_test                      0.971326\n",
      "accuracy_test                         0.972488\n",
      "confusion_matrix_test    [[710, 0], [23, 103]]\n",
      "Name: 48, dtype: object\n",
      "\n",
      "\n",
      "Model with the best weighted f1 according to the test set:\n",
      "model                                       LR\n",
      "lowercased                                True\n",
      "stopwords_removed                         True\n",
      "lemmatized                               False\n",
      "unigrams                                  True\n",
      "bigrams                                  False\n",
      "trigrams                                 False\n",
      "tfidf unigrams                           False\n",
      "tfidf bigrams                            False\n",
      "tfidf trigrams                           False\n",
      "f1_train                               0.98449\n",
      "weighted_f1_train                     0.995964\n",
      "accuracy_train                        0.995988\n",
      "f1_test                               0.941176\n",
      "weighted_f1_test                      0.982843\n",
      "accuracy_test                         0.983254\n",
      "confusion_matrix_test    [[710, 0], [14, 112]]\n",
      "Name: 36, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Model with the best weighted f1 according to the train set:\")\n",
    "print(df.iloc[df['weighted_f1_train'].idxmax()])\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Model with the best weighted f1 according to the test set:\")\n",
    "print(df.iloc[df['weighted_f1_test'].idxmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for best preforming model on test set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[710,   0],\n",
       "       [ 14, 112]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix for best preforming model on test set\n",
    "\n",
    "print(\"Confusion matrix for best preforming model on test set:\")\n",
    "df.iloc[df['weighted_f1_test'].idxmax()]['confusion_matrix_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top left number (710) refers to the true positive count, that is correctly predicted spam emails. The bottom right number (112) refers to the true negative count, correctly predicted non-spam. The top right number (0) refers to the false positive count, that is ham emails that have been labeled spam. And the bottom left number (14) refers to the false negative count, that is spam emails that have falsey been identified as ham emails. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the experiment for the best-performing combination of model type, preprocessing, and lexical features above, but this time limit the analysis to all the combinations of the parts-of-speeches below (total of 8 combinations):<br>\n",
    "\n",
    "(1) Adjectives <br>\n",
    "(2) Nouns  <br>\n",
    "(3) Verbs  <br>\n",
    "\n",
    "What this means is that after tokenization and before preprocessing, you remove all words that do not have the part of speech you are looking at. E.g., for the combination Adjectives & Nouns, all words that are not a noun or adjective should be removed. <br>\n",
    "\n",
    "That's 8 new models. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "verb_tags = ['VB','VBD','VBG','VBN','VBP','VBZ']\n",
    "adj_tags = ['JJ', 'JJR', 'JJS']\n",
    "noun_tags = ['NN','NNS','NNP','NNPS']\n",
    "\n",
    "def filter_tokens(tokens, include_adjectives, include_nouns, include_verbs):\n",
    "    filtered_tokens = []\n",
    "    \n",
    "    # Get POS tags from tokenized message\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    \n",
    "    for word, pos in pos_tags:       \n",
    "        if include_adjectives and pos in adj_tags:\n",
    "            filtered_tokens.append(word)\n",
    "        if include_nouns and pos in noun_tags:\n",
    "            filtered_tokens.append(word)\n",
    "        if include_verbs and pos in verb_tags:\n",
    "            filtered_tokens.append(word)\n",
    "        \n",
    "        # Exception: all False, words that are not adjectives, nouns, or verbs (adverbs, determiners, etc.) all come back in\n",
    "        if include_adjectives == False and include_nouns == False and include_verbs == False:\n",
    "            if (pos not in adj_tags) and (pos not in noun_tags) and (pos not in verb_tags):\n",
    "                filtered_tokens.append(word)\n",
    "        \n",
    "    return filtered_tokens\n",
    "    \n",
    "def filter_POS(spam_df, adjectives=True, nouns=True, verbs=True):\n",
    "    spam_df['Tokenized_Message'] = spam_df['Message'].apply(nltk.word_tokenize)\n",
    "    spam_df['Tokenized_Message'] = spam_df['Tokenized_Message'].apply(lambda x: filter_tokens(x, adjectives, nouns, verbs))   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The', 'over', 'the', '.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input_tokens = nltk.word_tokenize(\"The quick brown fox jumps over the lazy dog.\")\n",
    "# print(nltk.pos_tag(input_tokens))\n",
    "# filter_tokens(input_tokens, False, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adjectives</th>\n",
       "      <th>Nouns</th>\n",
       "      <th>Verbs</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>weighted_f1_test</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>confusion_matrix_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.924370</td>\n",
       "      <td>0.977941</td>\n",
       "      <td>0.978469</td>\n",
       "      <td>[[708, 2], [16, 110]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.918455</td>\n",
       "      <td>0.976496</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>[[710, 0], [19, 107]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.946195</td>\n",
       "      <td>0.949761</td>\n",
       "      <td>[[707, 3], [39, 87]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.642105</td>\n",
       "      <td>0.907091</td>\n",
       "      <td>0.918660</td>\n",
       "      <td>[[707, 3], [65, 61]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.970254</td>\n",
       "      <td>0.971292</td>\n",
       "      <td>[[708, 2], [22, 104]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.886957</td>\n",
       "      <td>0.967649</td>\n",
       "      <td>0.968900</td>\n",
       "      <td>[[708, 2], [24, 102]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.611399</td>\n",
       "      <td>0.898364</td>\n",
       "      <td>0.910287</td>\n",
       "      <td>[[702, 8], [67, 59]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.604396</td>\n",
       "      <td>0.899336</td>\n",
       "      <td>0.913876</td>\n",
       "      <td>[[709, 1], [71, 55]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Adjectives  Nouns  Verbs   f1_test  weighted_f1_test  accuracy_test  \\\n",
       "0        True   True   True  0.924370          0.977941       0.978469   \n",
       "1        True   True  False  0.918455          0.976496       0.977273   \n",
       "2        True  False   True  0.805556          0.946195       0.949761   \n",
       "3        True  False  False  0.642105          0.907091       0.918660   \n",
       "4       False   True   True  0.896552          0.970254       0.971292   \n",
       "5       False   True  False  0.886957          0.967649       0.968900   \n",
       "6       False  False   True  0.611399          0.898364       0.910287   \n",
       "7       False  False  False  0.604396          0.899336       0.913876   \n",
       "\n",
       "   confusion_matrix_test  \n",
       "0  [[708, 2], [16, 110]]  \n",
       "1  [[710, 0], [19, 107]]  \n",
       "2   [[707, 3], [39, 87]]  \n",
       "3   [[707, 3], [65, 61]]  \n",
       "4  [[708, 2], [22, 104]]  \n",
       "5  [[708, 2], [24, 102]]  \n",
       "6   [[702, 8], [67, 59]]  \n",
       "7   [[709, 1], [71, 55]]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best preforming model from Q1                                     \n",
    "# model                                     LR\n",
    "# lowercased                                True\n",
    "# stopwords_removed                         True\n",
    "# lemmatized                               False\n",
    "# unigrams                                  True\n",
    "# bigrams                                  False\n",
    "# trigrams                                 False\n",
    "# tfidf unigrams                           False\n",
    "# tfidf bigrams                            False\n",
    "# tfidf trigrams                           False\n",
    "\n",
    "df2 = pd.DataFrame(columns=['Adjectives','Nouns','Verbs', 'f1_test', \n",
    "                          'weighted_f1_test', 'accuracy_test', 'confusion_matrix_test'])\n",
    "\n",
    "row = []\n",
    "i=0\n",
    "for include_adjectives in [True, False]:\n",
    "    for include_nouns in [True, False]:\n",
    "        for include_verbs in [True, False]:\n",
    "            row.append(include_adjectives)\n",
    "            row.append(include_nouns)\n",
    "            row.append(include_verbs)\n",
    "            \n",
    "            filter_POS(spam_df, include_adjectives, include_nouns, include_verbs)\n",
    "            \n",
    "            res, cm = run_model(spam_df, category_numeric, 'LR', lowercase=True, remove_stopwords=True,\n",
    "                lemmatize=False, tfidf=False, ngram_range=(1,1))\n",
    "\n",
    "            row.extend(res[-3:])\n",
    "            row.append(cm)\n",
    "            \n",
    "            df2.loc[i] = row\n",
    "            i = i+1\n",
    "            row = []\n",
    "            \n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with the best weighted f1 according to the test set:\n",
      "Adjectives                                True\n",
      "Nouns                                     True\n",
      "Verbs                                     True\n",
      "f1_test                                0.92437\n",
      "weighted_f1_test                      0.977941\n",
      "accuracy_test                         0.978469\n",
      "confusion_matrix_test    [[708, 2], [16, 110]]\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Model with the best weighted f1 according to the test set:\")\n",
    "print(df2.iloc[df2['weighted_f1_test'].idxmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for best preforming model on test set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[708,   2],\n",
       "       [ 16, 110]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix for best preforming model on test set\n",
    "\n",
    "print(\"Confusion matrix for best preforming model on test set:\")\n",
    "df2.iloc[df2['weighted_f1_test'].idxmax()]['confusion_matrix_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the experiment for the best-performing model type from Q1 (i.e., LR or RF) using the following features (no preprocessing is required): <br>\n",
    "(1) Word2Vec features from GoogleNews (limit vocabulary to 40000 words) <br>\n",
    "(2) Features from a new Word2Vec model trained on the **train** set of your dataset. Use the following hyperparameters: window=5,vector_size=100 ,min_count=5 <br>\n",
    "\n",
    "You can average the semantic embeddings for the words in a document to create a single semantic vector for the document. You can ignore words that are not present in your Word2Vec model. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(spam_df, category_numeric, test_size=0.15, random_state=20)\n",
    "    \n",
    "    \n",
    "google_news_model = gensim.models.KeyedVectors.load_word2vec_format('../GoogleNews-vectors-negative300.bin', \n",
    "                                                                    binary=True, limit=40000)\n",
    "\n",
    "train_word2vec_model = Word2Vec(sentences=X_train['Message'].apply(lambda x: x.split()), \n",
    "                                window=5, vector_size=100, min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# averaging the semantic embeddings for a document\n",
    "\n",
    "def get_word2vec_features(text, w2vmodel):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    valid_words = [word for word in tokens if word in w2vmodel]\n",
    "\n",
    "    if valid_words:\n",
    "        return np.mean(w2vmodel[valid_words], axis=0)\n",
    "    else:\n",
    "        return np.zeros(w2vmodel.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google_news_semantic Features -  Weighted_f1 score: 0.9492811007888508\n",
      "train_word2vec_semantic Features -  Weighted_f1 score: 0.7800652401319659\n"
     ]
    }
   ],
   "source": [
    "# training semantic only\n",
    "vectors = ['google_news_semantic', 'train_word2vec_semantic']\n",
    "\n",
    "for vector in vectors:\n",
    "\n",
    "    X_train_raw = X_train['Message']\n",
    "    X_test_raw = X_test['Message']\n",
    "    \n",
    "    if vector == 'google_news_semantic': \n",
    "        X_train_array = np.array([get_word2vec_features(text, google_news_model) for text in X_train_raw])\n",
    "        X_test_array = np.array([get_word2vec_features(text, google_news_model) for text in X_test_raw])\n",
    "    elif vector == 'train_word2vec_semantic':\n",
    "        X_train_array = np.array([get_word2vec_features(text, train_word2vec_model.wv) for text in X_train_raw])\n",
    "        X_test_array = np.array([get_word2vec_features(text, train_word2vec_model.wv) for text in X_test_raw])\n",
    "        \n",
    "    model = train_model('LR', X_train_array, y_train)\n",
    "    \n",
    "    data = evaluate_model(model, 'weighted_f1', X_test_array, y_test)\n",
    "    \n",
    "    print(vector + \" Features -  Weighted_f1 score: \" + str(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The google news vector has better semantic features. Now combine with Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic only model: 0.9492811007888508\n",
      "Semantic and lexical model: 0.9879175677615438\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "X_train_raw = X_train['Message']\n",
    "X_test_raw = X_test['Message']\n",
    "X_train_array = np.array([get_word2vec_features(text, google_news_model) for text in X_train_raw])\n",
    "X_test_array = np.array([get_word2vec_features(text, google_news_model) for text in X_test_raw])\n",
    "\n",
    "Q3_A_model = train_model('LR', X_train_array, y_train)\n",
    "data = evaluate_model(Q3_A_model, 'weighted_f1', X_test_array, y_test)\n",
    "print(\"Semantic only model: \" + str(data))\n",
    "\n",
    "# Filter the dataset using parts of speech we found from Q2 \n",
    "filter_POS(X_train, True, True, True)\n",
    "filter_POS(X_test, True, True, True)\n",
    "\n",
    "X_train_filtered = X_train['Tokenized_Message'].apply(lambda x: ' '.join(x))\n",
    "X_test_filtered = X_test['Tokenized_Message'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1))\n",
    "features = vectorizer.fit_transform(X_train_filtered)\n",
    "test_features = vectorizer.transform(X_test_filtered)\n",
    "\n",
    "X_train_combined = np.concatenate([features.toarray(), X_train_array], axis=1)\n",
    "X_test_combined = np.concatenate([test_features.toarray(), X_test_array], axis=1)\n",
    "\n",
    "Q3_B_model = train_model(\"LR\", X_train_combined, y_train)\n",
    "\n",
    "data = evaluate_model(Q3_B_model, 'weighted_f1', X_test_combined, y_test)\n",
    "print(\"Semantic and lexical model: \" + str(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def run_model2(spam_df, y, model, combined_w_Q2=False):\n",
    "\n",
    "    # Assume spam has message and tokenized message\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(spam_df, y, test_size=0.15, random_state=20)\n",
    "    \n",
    "    X_train_array = np.array([get_word2vec_features(text, model) for text in X_train['Message']])\n",
    "    X_test_array = np.array([get_word2vec_features(text, model) for text in X_test['Message']])\n",
    "    \n",
    "    if combined_w_Q2: \n",
    "        filter_POS(X_train, True, True, True)\n",
    "        filter_POS(X_test, True, True, True)\n",
    "        \n",
    "        X_train_filtered = X_train['Tokenized_Message'].apply(lambda x: ' '.join(x))\n",
    "        X_test_filtered = X_test['Tokenized_Message'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "        vectorizer = CountVectorizer(ngram_range=(1,1))\n",
    "        features = vectorizer.fit_transform(X_train_filtered)\n",
    "        test_features = vectorizer.transform(X_test_filtered)\n",
    "\n",
    "        X_train_array = np.concatenate([features.toarray(), X_train_array], axis=1)\n",
    "        X_test_array = np.concatenate([test_features.toarray(), X_test_array], axis=1)\n",
    "\n",
    "    model = train_model(\"LR\", X_train_array, y_train)\n",
    "    \n",
    "    metrics_data = []\n",
    "\n",
    "    for metric in ['f1', 'weighted_f1', 'accuracy']:\n",
    "        data = evaluate_model(model, metric, X_test_array, y_test)\n",
    "        metrics_data.append(data)\n",
    "    \n",
    "    y_pred = model.predict(X_test_array)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return metrics_data, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>lowercased</th>\n",
       "      <th>stopwords_removed</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>nouns</th>\n",
       "      <th>verbs</th>\n",
       "      <th>all</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "      <th>tfidf unigrams</th>\n",
       "      <th>tfidf bigrams</th>\n",
       "      <th>tfidf trigrams</th>\n",
       "      <th>w2v_GoogleNews</th>\n",
       "      <th>w2v_Span</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>weighted_f1_test</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>confusion_matrix_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.982843</td>\n",
       "      <td>0.983254</td>\n",
       "      <td>[[710, 0], [14, 112]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.924370</td>\n",
       "      <td>0.977941</td>\n",
       "      <td>0.978469</td>\n",
       "      <td>[[708, 2], [16, 110]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3-A</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.824034</td>\n",
       "      <td>0.949281</td>\n",
       "      <td>0.950957</td>\n",
       "      <td>[[699, 11], [30, 96]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q3-B</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.959350</td>\n",
       "      <td>0.987918</td>\n",
       "      <td>0.988038</td>\n",
       "      <td>[[708, 2], [8, 118]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  lowercased  stopwords_removed  lemmatized  adjectives  nouns  verbs  \\\n",
       "0    Q1        True               True       False       False  False  False   \n",
       "1    Q2        True               True       False        True   True   True   \n",
       "2  Q3-A       False              False       False        True   True   True   \n",
       "3  Q3-B       False              False       False        True   True   True   \n",
       "\n",
       "    all  unigrams  bigrams  trigrams  tfidf unigrams  tfidf bigrams  \\\n",
       "0  True      True    False     False           False          False   \n",
       "1  True      True    False     False           False          False   \n",
       "2  True     False    False     False           False          False   \n",
       "3  True      True    False     False           False          False   \n",
       "\n",
       "   tfidf trigrams  w2v_GoogleNews  w2v_Span   f1_test  weighted_f1_test  \\\n",
       "0           False           False     False  0.941176          0.982843   \n",
       "1           False           False     False  0.924370          0.977941   \n",
       "2           False            True     False  0.824034          0.949281   \n",
       "3           False            True     False  0.959350          0.987918   \n",
       "\n",
       "   accuracy_test  confusion_matrix_test  \n",
       "0       0.983254  [[710, 0], [14, 112]]  \n",
       "1       0.978469  [[708, 2], [16, 110]]  \n",
       "2       0.950957  [[699, 11], [30, 96]]  \n",
       "3       0.988038   [[708, 2], [8, 118]]  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.DataFrame(columns=['model', 'lowercased','stopwords_removed', 'lemmatized', 'adjectives','nouns','verbs',\n",
    "                           'all', 'unigrams', 'bigrams', 'trigrams', 'tfidf unigrams', 'tfidf bigrams',\n",
    "                           'tfidf trigrams', 'w2v_GoogleNews', 'w2v_Span',\n",
    "                           'f1_test', 'weighted_f1_test', 'accuracy_test', 'confusion_matrix_test'])\n",
    "\n",
    "# Constants\n",
    "model_1 = [\"Q1\", True, True, False, False, False, False, True, True, False, False, False, False, False, False, False]\n",
    "model_2 = [\"Q2\", True, True, False, True, True, True, True, True, False, False, False, False, False, False, False]\n",
    "model_3 = [\"Q3-A\", False, False, False, True, True, True, True, False, False, False, False, False, False, True, False]\n",
    "model_4 = [\"Q3-B\", False, False, False, True, True, True, True, True, False, False, False, False, False, True, False]\n",
    "    \n",
    "row = []\n",
    "i=0\n",
    "for model in [model_1, model_2, model_3, model_4]:\n",
    "    row.extend(model)\n",
    "\n",
    "    if model[0] == 'Q2':\n",
    "        filter_POS(spam_df, True, True, True)\n",
    "        \n",
    "    if model[0] == 'Q1' or model[0] == 'Q2':\n",
    "        res, cm = run_model(spam_df, category_numeric, 'LR', lowercase=True, remove_stopwords=True,\n",
    "                        lemmatize=False, tfidf=False, ngram_range=(1,1))\n",
    "        res = res[-3:]\n",
    "\n",
    "    # assume the google news model is loaded in a previous kernal\n",
    "    if model[0] == 'Q3-A':\n",
    "        res, cm = run_model2(spam_df, category_numeric, google_news_model, combined_w_Q2=False)\n",
    "    \n",
    "    if model[0] == 'Q3-B':\n",
    "        res, cm = run_model2(spam_df, category_numeric, google_news_model, combined_w_Q2=True)\n",
    "    \n",
    "    row.extend(res)\n",
    "    row.append(cm)\n",
    "                \n",
    "    df3.loc[i] = row\n",
    "    i = i+1\n",
    "    row = []\n",
    "            \n",
    "df3.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with the best weighted f1 according to the test set:\n",
      "model                                    Q3-B\n",
      "lowercased                              False\n",
      "stopwords_removed                       False\n",
      "lemmatized                              False\n",
      "adjectives                               True\n",
      "nouns                                    True\n",
      "verbs                                    True\n",
      "all                                      True\n",
      "unigrams                                 True\n",
      "bigrams                                 False\n",
      "trigrams                                False\n",
      "tfidf unigrams                          False\n",
      "tfidf bigrams                           False\n",
      "tfidf trigrams                          False\n",
      "w2v_GoogleNews                           True\n",
      "w2v_Span                                False\n",
      "f1_test                               0.95935\n",
      "weighted_f1_test                     0.987918\n",
      "accuracy_test                        0.988038\n",
      "confusion_matrix_test    [[708, 2], [8, 118]]\n",
      "Name: 3, dtype: object\n",
      "\n",
      "\n",
      "Confusion matrix for best preforming model on test set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[708,   2],\n",
       "       [  8, 118]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Model with the best weighted f1 according to the test set:\")\n",
    "print(df3.iloc[df3['weighted_f1_test'].idxmax()])\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Confusion matrix for best preforming model on test set:\")\n",
    "df3.iloc[df3['weighted_f1_test'].idxmax()]['confusion_matrix_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to improve even more using grid search cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(spam_df, category_numeric, \n",
    "                                                    test_size=0.15, random_state=20)\n",
    "\n",
    "X_train_array = np.array([get_word2vec_features(text, google_news_model) for text in X_train['Message']])\n",
    "X_test_array = np.array([get_word2vec_features(text, google_news_model) for text in X_test['Message']])\n",
    "\n",
    "filter_POS(X_train, True, True, True)\n",
    "filter_POS(X_test, True, True, True)\n",
    "\n",
    "# Preprocessing couldn't seem to bring my score up\n",
    "\n",
    "X_train_filtered = X_train['Tokenized_Message'].apply(lambda x: ' '.join(x))\n",
    "X_test_filtered = X_test['Tokenized_Message'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1))\n",
    "features = vectorizer.fit_transform(X_train_filtered)\n",
    "test_features = vectorizer.transform(X_test_filtered)\n",
    "\n",
    "X_train_combined = np.concatenate([features.toarray(), X_train_array], axis=1)\n",
    "X_test_combined = np.concatenate([test_features.toarray(), X_test_array], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10,\n",
       " 'class_weight': 'balanced',\n",
       " 'max_iter': 1000,\n",
       " 'penalty': 'l2',\n",
       " 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "bonus_model = LogisticRegression()\n",
    "\n",
    "param_grid = {'penalty': ['l1', 'l2'],\n",
    "              'C': [0.1, 1, 10],\n",
    "              'solver': ['liblinear'],\n",
    "              'max_iter': [1000],\n",
    "              'class_weight': ['balanced']}\n",
    "\n",
    "bonus_model_tuned = GridSearchCV(bonus_model, param_grid=param_grid, error_score='raise', scoring='f1_weighted')\n",
    "bonus_model_tuned.fit(X_train_combined, y_train)\n",
    "bonus_model_tuned.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98417722 0.98521647 0.99155227 0.98099261 0.97676874]\n",
      "Bonus model Weighted F1 score: 0.9904306220095693\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# from last kernel\n",
    "bonus_model.set_params(**bonus_model_tuned.best_params_)\n",
    "bonus_model.fit(X_train_combined, y_train)\n",
    "\n",
    "print(cross_val_score(bonus_model, X_train_combined, y_train, cv=5))\n",
    "\n",
    "data = evaluate_model(bonus_model, 'weighted_f1', X_test_combined, y_test)\n",
    "\n",
    "print(\"Bonus model Weighted F1 score: \" + str(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
